# âœ‹ Sign Language Recognition

A **real-time hand gesture recognition system** built with **Python**, **OpenCV**, and **TensorFlow/Keras** that detects and classifies sign language hand gestures (digits 0â€“9). This project trains a convolutional neural network (CNN) using webcam-captured images to recognize hand signs and can be extended for broader gesture recognition tasks. :contentReference[oaicite:0]{index=0}

---

## ğŸš€ Features

- ğŸ“¸ **Real-time gesture capture** using webcam
- ğŸ§  **CNN model training** for accurate classification of hand gestures
- ğŸ“Š Simple folder-based dataset setup
- ğŸ› ï¸ Ready-to-run Python scripts for training and inference
- ğŸ“¦ Expandable for sign language letters and custom gestures

---

## ğŸ“ Repository Structure

Sign-Language-Recognition/
â”œâ”€â”€ create_gesture_data.py # Capture gesture images via webcam
â”œâ”€â”€ DataFlair_trainCNN.py # Train the CNN model
â”œâ”€â”€ model_for_gesture.py # Load & test the trained model
â”œâ”€â”€ dataset/ # Collected gesture images
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md

---

## ğŸ§  How It Works

1. **Capture images** of hand signs for each class (digit) using the webcam.  
2. Store captured images under class-named folders.  
3. Train the CNN model using these images.  
4. Use the trained model to classify live hand gestures.  

---

## ğŸ› ï¸ Getting Started

### ğŸ§¾ Prerequisites

Install Python 3.7+ and required libraries:

pip install -r requirements.txt
Make sure you have:

Python

OpenCV

TensorFlow / Keras

NumPy
ğŸ“¸ Step 1 â€” Collect Gesture Data

Run the data collection script:

python create_gesture_data.py


A window will open allowing you to capture images for each gesture class. Save enough images per class (50â€“200 recommended).

ğŸ§ª Step 2 â€” Train the Model

Train your CNN model on the captured dataset:

python DataFlair_trainCNN.py


This will generate a saved model file (e.g., model.h5) that can be used for prediction.

â–¶ï¸ Step 3 â€” Recognize Gestures

After training, run the inference script:

python model_for_gesture.py


This launches the webcam and displays detected gestures in real-time.

ğŸ“ˆ Results

Once trained, the model can recognize numeric sign gestures (0â€“9) with reasonable accuracy. You can expand this system to include:

Alphabet gestures (Aâ€“Z)

Sentence formation

Integration with Speech/Text output

ğŸ§© Contributions

Contributions, suggestions and improvements are very welcome!
To contribute:
Fork the repository â­

Create a new branch (git checkout -b feature/xyz)

Commit your changes

Open a Pull Request
